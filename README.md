# Titanic Data Analysis Pipeline

## Overview
This project analyzes the Titanic dataset to identify factors that influenced passenger survival. It includes data cleaning, feature engineering, and a Logistic Regression model.

## Files
- **note.ipynb**: Jupyter Notebook containing data analysis, visualization, and modeling.
- **new.py**: Python script to load cleaned data into a MySQL database.
- **cleaned_titanic.csv**: The processed dataset (generated by the notebook).

## Key Steps
1. **Data Cleaning**: Handled missing values in Age, Embarked, and Fare. Dropped the sparse Cabin column.
2. **Feature Engineering**: Created new features like `Title`, `FamilySize`, `IsAlone`, and binned Age/Fare.
3. **Modeling**: Trained a Logistic Regression model to predict survival with ~80% accuracy.

## Setup
1. Install dependencies:
   ```bash
   pip install pandas mysql-connector-python tqdm python-dotenv scikit-learn matplotlib seaborn
   ```
2. Run the notebook `note.ipynb` to generate the cleaned CSV.
3. Configure `.env` with your database credentials.
4. Run `new.py` to load data into MySQL.